{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9277dbc2-ff0e-4251-88a6-173dfb274e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vialla/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import brevitas\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.quant import Int8ActPerTensorFloat, Int8WeightPerTensorFloat\n",
    "from typing import Dict, List, Set, Optional, Callable\n",
    "from collections import OrderedDict\n",
    "import concrete\n",
    "from concrete.numpy.compilation import Configuration\n",
    "from concrete.ml.torch.compile import compile_brevitas_qat_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa7a5a0-9a7a-49e1-9492-279b641ddfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.1\n"
     ]
    }
   ],
   "source": [
    "print(concrete.ml.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315facf-e0f9-4d5b-90bd-c37ba31eefd8",
   "metadata": {},
   "source": [
    "# FP32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb507345-357f-4813-9a42-6ccb0619be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseClassifier(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(DenseClassifier, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.dense1 = nn.Linear(hparams['n_feats'], hparams['hidden_dim'])\n",
    "        self.dp1 = nn.Dropout(0.1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.dense2 = nn.Linear(hparams['hidden_dim'], 1)\n",
    "           \n",
    "    def forward(self, src):\n",
    "        x = self.dense1(src)\n",
    "        x = self.dp1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d29d0a-3b8f-41ef-aa87-ce1e951f8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'n_feats': 12,\n",
    "        'hidden_dim': 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c44b1c0-a08e-4655-82c1-d8fefb8a6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = DenseClassifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5207da0-a653-45b2-8677-c159c4dd9bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a70cf130-0150-4cec-b761-fecf4efbce22",
   "metadata": {},
   "source": [
    "# Quant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ac995c-1bd0-4feb-8ad9-3655b4e1c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QDenseClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hparams: dict,\n",
    "                 bits: int,\n",
    "                 act_quant: brevitas.quant = Int8ActPerTensorFloat,\n",
    "                 weight_quant: brevitas.quant = Int8WeightPerTensorFloat):\n",
    "        super(QDenseClassifier, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.dense1 = qnn.QuantLinear(hparams['n_feats'], hparams['hidden_dim'], weight_bit_width=bits, weight_quant=weight_quant, bias=True, return_quant_tensor=True)\n",
    "        self.dp1 = qnn.QuantDropout(0.1)\n",
    "        self.act1 = qnn.QuantReLU(act_quant=act_quant)\n",
    "        \n",
    "        self.dense2 = qnn.QuantLinear(hparams['hidden_dim'], 1, weight_bit_width=bits, weight_quant=weight_quant, bias=True, return_quant_tensor=True)\n",
    "            \n",
    "    def forward(self, src):\n",
    "        x = self.dense1(src)\n",
    "        x = self.dp1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefdd1b5-6ece-43cd-bf6a-d4e2c91c04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant = QDenseClassifier(config, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8df2ab-b60e-468a-80c9-36fe43258953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From concrete-ml VGG notebook\n",
    "def mapping_keys(pretrained_weights: Dict, model: nn.Module, device: str) -> nn.Module:\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize the quantized model with pre-trained fp32 weights.\n",
    "    Args:\n",
    "        pretrained_weights (Dict): The state_dict of the pre-trained fp32 model.\n",
    "        model (nn.Module): The Brevitas model.\n",
    "        device (str): Device type.\n",
    "    Returns:\n",
    "        Callable: The quantized model with the pre-trained state_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    # Brevitas requirement to ignore missing keys\n",
    "    brevitas.config.IGNORE_MISSING_KEYS = True\n",
    "\n",
    "    old_keys = list(pretrained_weights.keys())\n",
    "    new_keys = list(model.state_dict().keys())\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for old_key, new_key in zip(old_keys, new_keys):\n",
    "        new_state_dict[new_key] = pretrained_weights[old_key]\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1233402b-c157-42d5-94b2-6cb7b02de37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(model_quant.dense1.bias, model_fp32.dense1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6295e07b-d315-4d02-8b8a-dc59748daead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant = mapping_keys(model_fp32.state_dict(), model_quant, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd746dca-ed6c-49f9-a026-bd2f18c69734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(model_quant.dense1.bias, model_fp32.dense1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d94d39-7d61-469d-97be-0bdacfc75c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From concrete-ml VGG notebook\n",
    "def fhe_compatibility(model: Callable, bit: int, data: DataLoader) -> Callable:\n",
    "    \"\"\"Test if the model is FHE-compatible.\n",
    "    Args:\n",
    "        model (Callable): The Brevitas model.\n",
    "        bit (int): Bit of quantization.\n",
    "        data (DataLoader): The data loader.\n",
    "    Returns:\n",
    "        Callable: Quantized model.\n",
    "    \"\"\"\n",
    "    configuration = Configuration(\n",
    "        dump_artifacts_on_unexpected_failures=False,\n",
    "        # This is for our tests only, never use that in prod.\n",
    "        enable_unsafe_features=True,\n",
    "        # This is for our tests only, never use that in prod.\n",
    "        use_insecure_key_cache=True,\n",
    "        insecure_key_cache_location=\"ConcreteNumpyKeyCache\",\n",
    "        jit=False,\n",
    "        p_error=None,\n",
    "        global_p_error=None,\n",
    "    )\n",
    "\n",
    "    qmodel = compile_brevitas_qat_model(\n",
    "        model.to(\"cpu\"),\n",
    "        # Training\n",
    "        torch_inputset=data,\n",
    "        n_bits={\"model_inputs\": bit, \"op_inputs\": bit, \"op_weights\": bit, \"model_outputs\": bit},\n",
    "        configuration=configuration,\n",
    "        show_mlir=False,\n",
    "        # Set use_virtual_lib to False to use the real FHE execution.\n",
    "        use_virtual_lib=True,\n",
    "        # Concrete-ML uses table lookup (TLU) to represent any non-linear operation.\n",
    "        # This TLU is implemented through the Programmable Bootstrapping (PBS).\n",
    "        # A single PBS operation has P_ERROR chances of being incorrect.\n",
    "        # Default value = 6.3342483999973e-05.\n",
    "        p_error=6.3342483999973e-05,\n",
    "        output_onnx_file=\"test.onnx\",\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    return qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b292a2-3a5e-4da4-a6eb-69bd9024d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "data = torch.randn((batch_size, config['n_feats']))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d48e3a-f8c8-4cbf-8724-c525fa371d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx.brevitas.Quant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of onnx.brevitas::Quant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'node_integer_inputs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_quant2 \u001b[38;5;241m=\u001b[39m \u001b[43mfhe_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe maximum bit-width in the circuit = \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_quant2\u001b[38;5;241m.\u001b[39mforward_fhe\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mmaximum_integer_bit_width()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "Cell \u001b[0;32mIn [12], line 23\u001b[0m, in \u001b[0;36mfhe_compatibility\u001b[0;34m(model, bit, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Test if the model is FHE-compatible.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    model (Callable): The Brevitas model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Callable: Quantized model.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m configuration \u001b[38;5;241m=\u001b[39m Configuration(\n\u001b[1;32m     12\u001b[0m     dump_artifacts_on_unexpected_failures\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# This is for our tests only, never use that in prod.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     global_p_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m qmodel \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_brevitas_qat_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Training\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_inputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mop_inputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mop_weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mlir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Set use_virtual_lib to False to use the real FHE execution.\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_virtual_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Concrete-ML uses table lookup (TLU) to represent any non-linear operation.\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# This TLU is implemented through the Programmable Bootstrapping (PBS).\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# A single PBS operation has P_ERROR chances of being incorrect.\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Default value = 6.3342483999973e-05.\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6.3342483999973e-05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_onnx_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m clear_output()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qmodel\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/concrete/ml/torch/compile.py:349\u001b[0m, in \u001b[0;36mcompile_brevitas_qat_model\u001b[0;34m(torch_model, torch_inputset, n_bits, configuration, compilation_artifacts, show_mlir, use_virtual_lib, p_error, global_p_error, output_onnx_file, verbose_compilation)\u001b[0m\n\u001b[1;32m    346\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m remove_initializer_from_input(onnx_model)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Compile using the ONNX conversion flow, in QAT mode\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m q_module_vl \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_onnx_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_qat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompilation_artifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompilation_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mlir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_mlir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_virtual_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_virtual_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_p_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_p_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_compilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_compilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Remove the tempfile if we used one\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_tempfile:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/concrete/ml/torch/compile.py:253\u001b[0m, in \u001b[0;36mcompile_onnx_model\u001b[0;34m(onnx_model, torch_inputset, import_qat, configuration, compilation_artifacts, show_mlir, n_bits, use_virtual_lib, p_error, global_p_error, verbose_compilation)\u001b[0m\n\u001b[1;32m    246\u001b[0m onnx_model_opset_version \u001b[38;5;241m=\u001b[39m get_onnx_opset_version(onnx_model)\n\u001b[1;32m    247\u001b[0m assert_true(\n\u001b[1;32m    248\u001b[0m     onnx_model_opset_version \u001b[38;5;241m==\u001b[39m OPSET_VERSION_FOR_ONNX_EXPORT,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX version must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOPSET_VERSION_FOR_ONNX_EXPORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut it is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_model_opset_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m )\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_torch_or_onnx_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_inputset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_qat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompilation_artifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompilation_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_mlir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_mlir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_virtual_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_virtual_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_p_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_p_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_compilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_compilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/concrete/ml/torch/compile.py:119\u001b[0m, in \u001b[0;36m_compile_torch_or_onnx_model\u001b[0;34m(model, torch_inputset, import_qat, configuration, compilation_artifacts, show_mlir, n_bits, use_virtual_lib, p_error, global_p_error, verbose_compilation)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     post_training_quant \u001b[38;5;241m=\u001b[39m PostTrainingAffineQuantization(n_bits, numpy_model, is_signed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 119\u001b[0m quantized_module \u001b[38;5;241m=\u001b[39m \u001b[43mpost_training_quant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputset_as_numpy_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m quantized_numpy_inputset \u001b[38;5;241m=\u001b[39m quantized_module\u001b[38;5;241m.\u001b[39mquantize_input(\u001b[38;5;241m*\u001b[39minputset_as_numpy_tuple)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Don't let the user shoot in her foot, by having p_error or global_p_error set in both\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# configuration and in direct arguments\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/concrete/ml/quantization/post_training.py:549\u001b[0m, in \u001b[0;36mONNXConverter.quantize_module\u001b[0;34m(self, *calibration_data)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# First transform all parameters to their quantized version\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quantize_params()\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcalibration_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# Create quantized module from self.quant_layers_dict\u001b[39;00m\n\u001b[1;32m    552\u001b[0m quantized_module \u001b[38;5;241m=\u001b[39m QuantizedModule(\n\u001b[1;32m    553\u001b[0m     (graph_input\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m graph_input \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_model\u001b[38;5;241m.\u001b[39monnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minput),\n\u001b[1;32m    554\u001b[0m     (graph_output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m graph_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_model\u001b[38;5;241m.\u001b[39monnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39moutput),\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_ops_dict,\n\u001b[1;32m    556\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/concrete/ml/quantization/post_training.py:501\u001b[0m, in \u001b[0;36mONNXConverter._quantize_layers\u001b[0;34m(self, *input_calibration_data)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_op_type(node) \u001b[38;5;241m==\u001b[39m QuantizedBrevitasQuant\u001b[38;5;241m.\u001b[39mop_type():\n\u001b[1;32m    498\u001b[0m     list_real_cst_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(real_cst_inputs)\n\u001b[1;32m    499\u001b[0m     quantizer \u001b[38;5;241m=\u001b[39m QuantizedBrevitasQuant(\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bits_model_outputs,\n\u001b[0;32m--> 501\u001b[0m         \u001b[43mnode_integer_inputs\u001b[49m,\n\u001b[1;32m    502\u001b[0m         {\n\u001b[1;32m    503\u001b[0m             \u001b[38;5;241m1\u001b[39m: list_real_cst_inputs[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    504\u001b[0m             \u001b[38;5;241m2\u001b[39m: list_real_cst_inputs[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    505\u001b[0m             \u001b[38;5;241m3\u001b[39m: list_real_cst_inputs[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m    506\u001b[0m         },\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_input_quant_opts(curr_calibration_data, quantized_op_class),\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattributes,\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# The values to quantize may be stored in a QuantizedArray (for initializers\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# and constants), but they can also be float (produced by some other folded\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# operation).\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     constant_values_to_quantize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    514\u001b[0m         curr_cst_inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(curr_cst_inputs[\u001b[38;5;241m0\u001b[39m], QuantizedArray)\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bits_op_weights, curr_cst_inputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    517\u001b[0m     )\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'node_integer_inputs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model_quant2 = fhe_compatibility(model_quant, 7, data)\n",
    "print(\n",
    "    f\"The maximum bit-width in the circuit = \"\n",
    "    f\"{model_quant2.forward_fhe.graph.maximum_integer_bit_width()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf749c-26fb-4e4b-bcbe-911a9af8e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1746b-233a-4275-8980-439f9aaa2a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
